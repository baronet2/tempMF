{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cba4b44",
   "metadata": {},
   "source": [
    "## Import and Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8b842d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d12a6485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7c50c55240>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seeds \n",
    "seed = 12341\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 808
    },
    "id": "fdfd55e6",
    "outputId": "91c0b3df-e2c9-4ac7-b083-113ddcc46721",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1147880044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>306</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1147868817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1147868828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1147878820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>899</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1147868510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1      296     1.0  1147880044\n",
       "1       1      306     0.7  1147868817\n",
       "2       1      307     1.0  1147868828\n",
       "3       1      665     1.0  1147878820\n",
       "4       1      899     0.7  1147868510"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/ml-25m/ratings.csv\").dropna().head(10000)\n",
    "train['rating'] = train['rating'] / train['rating'].max()\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d77006",
   "metadata": {},
   "source": [
    "## preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b811ce01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix(df):\n",
    "    R = torch.zeros([df['userId'].max(), df['movieId'].max()])\n",
    "    for _, row in df.iterrows():\n",
    "        R[int(row['userId'] - 1), int(row['movieId']) - 1] = row['rating']\n",
    "    return R\n",
    "\n",
    "def get_temporal_matrix(old_df, t_steps):\n",
    "    df = old_df[:]\n",
    "    df['bin'] = pd.cut(df.timestamp, bins = t_steps, labels=range(t_steps))\n",
    "    R = torch.zeros([df['userId'].max(), df['movieId'].max(), t_steps])\n",
    "    for _, row in df.iterrows():\n",
    "        R[int(row['userId'] - 1), int(row['movieId']) - 1, row['bin']] = row['rating']\n",
    "    return R, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "438eddc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/udit/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([75, 203519])\n",
      "torch.Size([75, 203519, 100])\n"
     ]
    }
   ],
   "source": [
    "time_steps = 100\n",
    "\n",
    "R = get_matrix(train)\n",
    "R_t, train_updated = get_temporal_matrix(train, t_steps=time_steps)\n",
    "\n",
    "print(R.shape)\n",
    "print(R_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc849f6e",
   "metadata": {},
   "source": [
    "## PMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c3ca5f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import RandomState\n",
    "\n",
    "class PMF(nn.Module):\n",
    "\tdef __init__(self, n_users, n_items, n_factors=20, is_sparse=False, no_cuda=None):\n",
    "\t\tsuper(PMF, self).__init__()\n",
    "\t\tself.n_users = n_users\n",
    "\t\tself.n_items = n_items\n",
    "\t\tself.n_factors = n_factors\n",
    "\t\tself.random_state = RandomState(1)\n",
    "\n",
    "\t\t# M,D\n",
    "\t\tself.user_embeddings = nn.Embedding(n_users, n_factors, sparse=is_sparse)\n",
    "\t\tself.user_embeddings.weight.data = torch.from_numpy(0.1 * self.random_state.rand(n_users, n_factors)).float()\n",
    "\t\t\n",
    "\t\t# NxD\n",
    "\t\tself.item_embeddings = nn.Embedding(n_items, n_factors, sparse=is_sparse)\n",
    "\t\tself.item_embeddings.weight.data = torch.from_numpy(0.1 * self.random_state.rand(n_items, n_factors)).float()\n",
    "\n",
    "\n",
    "\t\tself.relu = nn.ReLU()\n",
    "\t\n",
    "\tdef forward(self, users_index=None, items_index=None):\n",
    "\t\tif users_index!=None and items_index!=None:\n",
    "\t\t\tuser_h1 = self.user_embeddings(users_index)\n",
    "\t\t\titem_h1 = self.item_embeddings(items_index)\n",
    "\t\t\t# print(user_h1.shape)\n",
    "\t\t\t# print(item_h1.shape)\n",
    "\t\t\t# R_h = (user_h1 * item_h1).sum(1)\n",
    "\t\t\tR_h = torch.dot(user_h1, item_h1)\n",
    "\t\telse:\n",
    "\t\t\tR_h = self.item_embeddings.weight.data @ self.user_embeddings.weight.data.T\n",
    "\t\treturn R_h\n",
    "\n",
    "\tdef __call__(self, *args):\n",
    "\t\treturn self.forward(*args)\n",
    "\n",
    "\n",
    "\tdef predict(self, users_index=None, items_index=None):\n",
    "\t\t# preds = self.forward(users_index, items_index)\n",
    "\t\tif users_index and items_index:\n",
    "\t\t\tpreds = self.forward(users_index, items_index)\n",
    "\t\telse:\n",
    "\t\t\tuser_h1 = self.user_embeddings(users_index)\n",
    "\t\t\titem_h1 = self.item_embeddings(items_index)\n",
    "\t\t\tpreds = (user_h1 * item_h1).sum(1)\n",
    "\t\treturn preds\n",
    "\n",
    "\n",
    "def RMSE(preds, truth):\n",
    "    return np.sqrt(np.mean(np.square(preds-truth)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2b8b2f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_embeddings.weight torch.Size([75, 20])\n",
      "item_embeddings.weight torch.Size([203519, 20])\n",
      "\n",
      "\n",
      "epoch 1\n",
      "epoch 2\n",
      "epoch 3\n",
      "epoch 4\n",
      "epoch 5\n",
      "epoch 6\n",
      "epoch 7\n",
      "epoch 8\n",
      "epoch 9\n",
      "epoch 10\n"
     ]
    }
   ],
   "source": [
    "model = PMF(n_users=R.shape[0], n_items=R.shape[1], n_factors=20)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data.shape)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "lr = 0.1\n",
    "reg = 0.01\n",
    "\n",
    "loss_SGD = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    print(\"epoch\", i + 1)\n",
    "\n",
    "    for _, row in train.iterrows():\n",
    "      user, item = torch.tensor(int(row['userId']) - 1), torch.tensor(int(row['movieId']) - 1)\n",
    "      # making a pridiction in forward pass\n",
    "      y_hat = model.forward(users_index=user, items_index=item)\n",
    "      error = R[user, item] - y_hat\n",
    "\n",
    "      # updates\n",
    "      # Pi ← Pi + α(eij Qj − λPi ) \n",
    "      model.user_embeddings.weight.data[user, :] = \\\n",
    "        model.user_embeddings.weight.data[user, :] + \\\n",
    "        lr * (error * model.item_embeddings.weight.data[item, :] - reg * model.user_embeddings.weight.data[user, :])\n",
    "      # Qj ← Qj + α(eij Pi − λQj )\n",
    "      model.item_embeddings.weight.data[item, :] = \\\n",
    "        model.item_embeddings.weight.data[item, :] + \\\n",
    "        lr * (error * model.user_embeddings.weight.data[user, :] - reg * model.item_embeddings.weight.data[item, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d82c0f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.7000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.8000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.6000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.linalg.norm(R - model().T)\n",
    "# torch.linalg.norm(R)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7bba5b",
   "metadata": {},
   "source": [
    "## TempMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "e3d9b5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import RandomState\n",
    "\n",
    "class TempMF(nn.Module):\n",
    "\tdef __init__(self, n_users, t_steps, item_embeddings, n_factors=20, is_sparse=False, no_cuda=None):\n",
    "\t\tsuper(PMF, self).__init__()\n",
    "\t\tself.n_users = n_users\n",
    "\n",
    "\t\tself.n_factors = n_factors\n",
    "\t\tself.random_state = RandomState(1)\n",
    "\n",
    "\t\t# M,D,t\n",
    "\t\tself.user_embeddings = nn.Embedding(n_users, n_factors, t_steps, sparse=is_sparse)\n",
    "\t\tself.user_embeddings.weight.data = torch.from_numpy(0.1 * self.random_state.rand(n_users, n_factors)).float()\n",
    "\t\t# N,D\n",
    "\t\tself.item_embeddings = item_embeddings\n",
    "\n",
    "\t\tself.relu = nn.ReLU()\n",
    "\t\n",
    "\tdef forward(self, time_index, users_index=None, items_index=None):\n",
    "\t\tif users_index!=None and items_index!=None:\n",
    "\t\t\tuser_h1 = self.user_embeddings.weight.data[users_index,:,time_index]\n",
    "\t\t\titem_h1 = self.item_embeddings(items_index)\n",
    "\t\t\t# print(user_h1.shape)\n",
    "\t\t\t# print(item_h1.shape)\n",
    "\t\t\t# R_h = (user_h1 * item_h1).sum(1)\n",
    "\t\t\tR_h = torch.dot(user_h1, item_h1)\n",
    "\t\telse:\n",
    "\t\t\tR_h = self.item_embeddings.weight.data @ self.user_embeddings.weight.data[:,:,time_index].T\n",
    "\t\treturn R_h\n",
    "\n",
    "\tdef __call__(self, *args):\n",
    "\t\treturn self.forward(*args)\n",
    "\n",
    "\n",
    "\tdef predict(self, time_index, users_index=None, items_index=None):\n",
    "\t\tpreds = self.forward(time_index, users_index, items_index)\n",
    "\t\treturn preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c7e57d4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-178-2e38045b5761>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtempMF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTempMF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_users\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_users\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_factors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_factors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-177-3db329b35f6b>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n_users, t_steps, item_embeddings, n_factors, is_sparse, no_cuda)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mTempMF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_users\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_factors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_cuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                 \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPMF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_users\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_users\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "tempMF = TempMF(n_users=model.n_users, t_steps=time_steps, item_embeddings=model.item_embeddings, n_factors=model.n_factors)\n",
    "\n",
    "epochs = 10\n",
    "lr = 0.1\n",
    "reg = 0.01\n",
    "\n",
    "loss_SGD = []\n",
    "\n",
    "# time\n",
    "for t in range(time_steps):\n",
    "    print(\"time:\", i + 1)\n",
    "    tempMF.user_embeddings.weight.data[:,:,t] = model.user_embeddings.weight.data\n",
    "\n",
    "    # iterations\n",
    "    for iter in range(epochs):\n",
    "      print('iter:', iter + 1)\n",
    "\n",
    "      # ratings\n",
    "      for _, row in train_updated[train_updated['bin'] == t].iterrows():\n",
    "        user, item = torch.tensor(int(row['userId']) - 1), torch.tensor(int(row['movieId']) - 1)\n",
    "        # making a pridiction in forward pass\n",
    "        y_hat = tempMF.forward(time_index=t, users_index=user, items_index=item)\n",
    "        error = R_t[user, item, t] - y_hat\n",
    "\n",
    "        tempMF.user_embeddings.weight.data[user, :, t] = \\\n",
    "          tempMF.user_embeddings.weight.data[user, :, t] + \\\n",
    "          lr * (error * tempMF.item_embeddings.weight.data[item, :] - reg * tempMF.user_embeddings.weight.data[user, :, t])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8f1874",
   "metadata": {},
   "source": [
    "#### iteration through time"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "'Python Interactive'",
   "language": "python",
   "name": "0eb7c0a6-5965-4378-80ef-67b5f65ff502"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
